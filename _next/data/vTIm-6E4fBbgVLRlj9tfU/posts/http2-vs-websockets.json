{"pageProps":{"post":{"id":"http2-vs-websockets","title":"HTTP2 vs WebSockets: a study of dashboard performance","date":"2018-12-20","excerpt":"<p>In this post, we will compare the performance of different approaches to load data for analytics dashboards, or any page where we have lots of different requests to the same server.</p>","content":"<p>In this post, we will compare the performance of different approaches to load data for analytics dashboards, or any page where we have lots of different requests to the same server.</p>\n<h2>Baseline</h2>\n<p>We will start from sample dashboard created with Vue.js and Chart.js (which does not matter) and loaded over HTTP/1.1 (which does matter). It should look like this, and appearance of it would not change till the end of this article, but we will try to change how quickly it appears in the browser window:</p>\n<p><img src=\"/content/dashboard.png\" alt=\"Example dashboard\" title=\"Our sample dashboard\"></p>\n<p>Static content will be served by Nginx server, which would also be a proxy to our backend python server which would serve data. It will expose 8080 port for HTTP and 8083 for HTTPS:</p>\n<p>(If you are bored with lot's of code - scroll down, there will be explanations of what happens, I just publish it here to make this experiment reproducible)</p>\n<pre><code class=\"hljs language-yml\"><span class=\"hljs-attr\">version:</span> <span class=\"hljs-string\">'3'</span>\n<span class=\"hljs-attr\">services:</span>\n    <span class=\"hljs-attr\">server:</span>\n        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">server</span>\n        <span class=\"hljs-attr\">build:</span>\n            <span class=\"hljs-attr\">context:</span> <span class=\"hljs-string\">.</span>\n            <span class=\"hljs-attr\">dockerfile:</span> <span class=\"hljs-string\">nginx.docker</span>\n        <span class=\"hljs-attr\">ports:</span>\n            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-number\">8080</span><span class=\"hljs-string\">:80</span>\n            <span class=\"hljs-bullet\">-</span> <span class=\"hljs-number\">8083</span><span class=\"hljs-string\">:443</span>\n    <span class=\"hljs-attr\">backend:</span>\n        <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">backend</span>\n        <span class=\"hljs-attr\">build:</span>\n            <span class=\"hljs-attr\">context:</span> <span class=\"hljs-string\">.</span>\n            <span class=\"hljs-attr\">dockerfile:</span> <span class=\"hljs-string\">backend.docker</span></code></pre>\n<p>Nginx container just runs image with a copy of configuration file and our HTML inside:</p>\n<pre><code class=\"hljs language-docker\"><span class=\"hljs-keyword\">FROM</span> nginx\n\n<span class=\"hljs-keyword\">COPY</span><span class=\"bash\"> nginx.conf /etc/nginx/nginx.conf</span>\n<span class=\"hljs-keyword\">COPY</span><span class=\"bash\"> dashboard.html /var/www/index.html</span></code></pre>\n<p>And this is its configuration file. It tells to listen at port 80, serve files from <code>/var/www</code>, and redirect requests to all URLs that have prefix <code>/api/</code> to our backend container:</p>\n<pre><code>user nginx;\n\nevents {\n  worker_connections 1024;\n}\n\nhttp {\n    sendfile on;\n    \n    include /etc/nginx/mime.types;\n\n    server {\n        listen 80;\n\n        root /var/www;\n\n        location /api/ {\n            proxy_pass      http://backend:8080/;\n        }\n    }\n}\n</code></pre>\n<p>Here is Dockerfile for backend server:</p>\n<pre><code class=\"hljs language-docker\"><span class=\"hljs-keyword\">FROM</span> python:<span class=\"hljs-number\">3.7</span>\n\n<span class=\"hljs-keyword\">ENV</span> PYTHONUNBUFFERED <span class=\"hljs-number\">1</span>\n<span class=\"hljs-keyword\">RUN</span><span class=\"bash\"> mkdir /code</span>\n<span class=\"hljs-keyword\">WORKDIR</span><span class=\"bash\"> /code</span>\n\n<span class=\"hljs-keyword\">RUN</span><span class=\"bash\"> pip install sanic</span>\n<span class=\"hljs-keyword\">COPY</span><span class=\"bash\"> server.py /code/server.py</span>\n\n<span class=\"hljs-keyword\">EXPOSE</span> <span class=\"hljs-number\">8080</span>\n\n<span class=\"hljs-keyword\">CMD</span><span class=\"bash\"> python /code/server.py</span></code></pre>\n<p>It has Python3.7 inside, installs Sanic framework, exposes port 8080 and runs <code>server.py</code>, which will provide us with data:</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">import</span> random\n\n<span class=\"hljs-keyword\">from</span> sanic <span class=\"hljs-keyword\">import</span> Sanic\n<span class=\"hljs-keyword\">from</span> sanic.response <span class=\"hljs-keyword\">import</span> json <span class=\"hljs-keyword\">as</span> json_response\n\napp = Sanic() <span class=\"hljs-comment\"># It is almost like Flask, just asyncronous</span>\n\n<span class=\"hljs-meta\">@app.route(<span class=\"hljs-params\"><span class=\"hljs-string\">'/data/&#x3C;data:int>'</span></span>)</span>\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">return_data</span>(<span class=\"hljs-params\">request, data</span>):</span>\n    <span class=\"hljs-keyword\">return</span> json_response(<span class=\"hljs-keyword\">await</span> get_data(\n        data, <span class=\"hljs-built_in\">int</span>(request.args.get(<span class=\"hljs-string\">'size'</span>, <span class=\"hljs-number\">10</span>))\n    ))\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">get_data</span>(<span class=\"hljs-params\">data, size</span>):</span>\n    <span class=\"hljs-comment\"># First we wait 1-5 seconds to simulate request to database</span>\n    <span class=\"hljs-keyword\">await</span> asyncio.sleep(<span class=\"hljs-number\">1</span> + random.random() * <span class=\"hljs-number\">4</span>)\n\n    <span class=\"hljs-comment\"># then start random walk from point that equals to data given</span>\n    <span class=\"hljs-comment\"># This is done to be able to distinguish between different graphs</span>\n    position = data\n    data = []\n    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(size):\n        position += random.random() - <span class=\"hljs-number\">0.5</span>\n        data.append(position)\n    <span class=\"hljs-comment\"># And return the data of that random walk</span>\n    <span class=\"hljs-keyword\">return</span> data\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">'__main__'</span>:\n    app.run(host=<span class=\"hljs-string\">'0.0.0.0'</span>, port=<span class=\"hljs-number\">8080</span>)\n</code></pre>\n<p>And the biggest listing in this post - HTML (well, mostly JavaScript) of the dashboard:</p>\n<pre><code class=\"hljs language-html\"><span class=\"hljs-meta\">&#x3C;!DOCTYPE <span class=\"hljs-meta-keyword\">html</span>></span>\n<span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">html</span>></span>\n<span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">head</span>></span>\n    <span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">meta</span> <span class=\"hljs-attr\">charset</span>=<span class=\"hljs-string\">\"UTF-8\"</span>></span>\n    <span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">title</span>></span>Dashboard<span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">title</span>></span>\n    <span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">style</span>></span><span class=\"css\">\n        <span class=\"hljs-selector-class\">.chart</span> {\n            <span class=\"hljs-attribute\">width</span>: <span class=\"hljs-number\">350px</span>; <span class=\"hljs-attribute\">height</span>: <span class=\"hljs-number\">200px</span>;\n            <span class=\"hljs-attribute\">margin</span>: <span class=\"hljs-number\">3px</span>; <span class=\"hljs-attribute\">border</span>: <span class=\"hljs-number\">1px</span> solid black;\n            <span class=\"hljs-attribute\">position</span>: relative; <span class=\"hljs-attribute\">float</span>: left;\n        }\n    </span><span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">style</span>></span>\n<span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">head</span>></span>\n\n<span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">body</span>></span>\n    <span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">\"app\"</span>></span>\n        <span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">p</span>></span>Loaded charts: {{loaded_chart_count}}<span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">p</span>></span>\n        <span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">div</span> <span class=\"hljs-attr\">v-for</span>=<span class=\"hljs-string\">\"chart in charts\"</span> <span class=\"hljs-attr\">class</span>=<span class=\"hljs-string\">\"chart\"</span>></span>\n            <span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">chart</span> <span class=\"hljs-attr\">:widget</span>=<span class=\"hljs-string\">\"chart\"</span> <span class=\"hljs-attr\">v-once</span>></span><span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">chart</span>></span>\n        <span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">div</span>></span>\n    <span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">div</span>></span>\n  \n<span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">script</span> <span class=\"hljs-attr\">src</span>=<span class=\"hljs-string\">'https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.7.3/Chart.min.js'</span>></span><span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">script</span>></span>\n<span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">script</span> <span class=\"hljs-attr\">src</span>=<span class=\"hljs-string\">'https://cdnjs.cloudflare.com/ajax/libs/lodash.js/4.17.11/lodash.min.js'</span>></span><span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">script</span>></span>\n<span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">script</span> <span class=\"hljs-attr\">src</span>=<span class=\"hljs-string\">'https://cdnjs.cloudflare.com/ajax/libs/vue/2.5.21/vue.min.js'</span>></span><span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">script</span>></span>\n\n<span class=\"hljs-tag\">&#x3C;<span class=\"hljs-name\">script</span> ></span><span class=\"javascript\">\n<span class=\"hljs-built_in\">console</span>.time(<span class=\"hljs-string\">'load'</span>); <span class=\"hljs-comment\">// Measure time from here to end of load</span>\n<span class=\"hljs-keyword\">const</span> DATA_LEN = <span class=\"hljs-number\">50</span>;\n<span class=\"hljs-keyword\">const</span> CHARTS_COUNT = <span class=\"hljs-number\">50</span>;\n\n<span class=\"hljs-keyword\">var</span> data = {\n    <span class=\"hljs-attr\">charts</span>: _.range(CHARTS_COUNT),\n    <span class=\"hljs-attr\">loaded_chart_count</span>: <span class=\"hljs-number\">0</span>,\n};\n\n\nVue.component(<span class=\"hljs-string\">'chart'</span>, {\n  <span class=\"hljs-attr\">template</span>: <span class=\"hljs-string\">'&#x3C;canvas width=\"350\" height=\"200\">&#x3C;/canvas>'</span>,\n  <span class=\"hljs-attr\">props</span>: [<span class=\"hljs-string\">'widget'</span>],\n  <span class=\"hljs-attr\">mounted</span>: <span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span>(<span class=\"hljs-params\"></span>) </span>{\n    createChart(<span class=\"hljs-built_in\">this</span>.$el, <span class=\"hljs-built_in\">this</span>.widget);\n  }\n});\n\n<span class=\"hljs-keyword\">var</span> createChart = <span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span>(<span class=\"hljs-params\">el, widget</span>) </span>{\n    <span class=\"hljs-comment\">// Load data and render line chart in given element</span>\n    loadData(widget, <span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span>(<span class=\"hljs-params\">chart_data</span>) </span>{\n      <span class=\"hljs-keyword\">new</span> Chart(el, {\n          <span class=\"hljs-attr\">type</span>: <span class=\"hljs-string\">'line'</span>,\n          <span class=\"hljs-attr\">data</span>: {\n              <span class=\"hljs-attr\">labels</span>: _.range(chart_data.length),\n              <span class=\"hljs-attr\">datasets</span>: [{\n                  <span class=\"hljs-attr\">label</span>: <span class=\"hljs-string\">'Data '</span> + widget,\n                  <span class=\"hljs-attr\">data</span>: chart_data,\n              }]\n          },\n      });\n      data.loaded_chart_count ++;\n      <span class=\"hljs-keyword\">if</span>(data.loaded_chart_count == CHARTS_COUNT) {\n        <span class=\"hljs-built_in\">console</span>.timeEnd(<span class=\"hljs-string\">'load'</span>); <span class=\"hljs-comment\">// stop load timer</span>\n      }\n    });\n};\n\n<span class=\"hljs-keyword\">new</span> Vue({\n  <span class=\"hljs-attr\">el</span>: <span class=\"hljs-string\">\"#app\"</span>,\n  <span class=\"hljs-attr\">data</span>: data\n});\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span> <span class=\"hljs-title\">loadData</span>(<span class=\"hljs-params\">widget, cb</span>) </span>{\n    <span class=\"hljs-comment\">// Load data for widget given, and when it is loaded - call cb</span>\n    fetch(<span class=\"hljs-string\">'/api/data/'</span> + widget + <span class=\"hljs-string\">'?size='</span> + DATA_LEN).then(<span class=\"hljs-function\"><span class=\"hljs-params\">res</span> =></span> res.json()).then(cb);\n}\n</span><span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">script</span>></span>\n<span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">body</span>></span>\n<span class=\"hljs-tag\">&#x3C;/<span class=\"hljs-name\">html</span>></span></code></pre>\n<p>It loads Charts.js and Vue using CDN and renders <code>CHARTS_COUNT</code> charts. We will work here with the function <code>loadData()</code>, to see what we could improve. But first - test our baseline. Run <code>docker-compose up</code> and check how quickly it loads. We could do it in browser console using <code>console.time</code>, and on network tab:</p>\n<p><img src=\"/content/network_debug.png\" alt=\"\" title=\"Screenshot of network tab of browser debugger\"></p>\n<p>29 seconds for 50 graphs? When all the JavaScript was loaded from cache? Not cool. Not cool at all.</p>\n<h2>Debugging the problem</h2>\n<p>But why it takes so much? Lets open request details:</p>\n<p><img src=\"/content/request_timings.png\" alt=\"\" title=\"Time of separate request\"></p>\n<p>We see that 24 seconds are spent in <strong>Blocked</strong> state, and 4.5 in <strong>Waiting</strong>, everything else is negligible. Here what <a href=\"https://developer.mozilla.org/en-US/docs/Tools/Network_Monitor/request_details#Timings\">Mozilla documentation</a> has to say about that states:</p>\n<blockquote>\n<ul>\n<li>\n<p><strong>Blocked:</strong> Time spent in a queue waiting for a network connection.</p>\n<p>The browser imposes a limit on the number of simultaneous connections that can be made to a single server. In Firefox this defaults to 6, but can be changed using the network.http.max-persistent-connections-per-server preference. If all connections are in use, the browser can't download more resources until a connection is released.</p>\n</li>\n<li>\n<p><strong>Waiting:</strong> Waiting for a response from the server.</p>\n</li>\n</ul>\n</blockquote>\n<p>Let's assume that we optimized everything we could about time of request processing on the server because my post is not about this. What could we do about time spent blocked? Could we increase the limit of simultaneous connections in a browser? <a href=\"https://tools.ietf.org/html/rfc2616#section-8.1.4\">RFC 2616</a> (document that defines HTTP/1.1) does not recommend this, and Firefox already has that amount higher than recommended:</p>\n<blockquote>\n<p>Clients that use persistent connections SHOULD limit the number of\nsimultaneous connections that they maintain to a given server. A\nsingle-user client SHOULD NOT maintain more than 2 connections with\nany server or proxy. A proxy SHOULD use up to 2 * N connections to\nanother server or proxy, where N is the number of simultaneously\nactive users. These guidelines are intended to improve HTTP response\ntimes and avoid congestion.</p>\n</blockquote>\n<p>There are other solutions, like <a href=\"https://medium.com/@jperasmus11/domain-sharding-on-the-modern-web-dc97df4f6a90\">domain sharding</a> where we duplicate our resources on different domains, so this limit is not applicable, but it requires configuring other domains on Nginx, updating front-end to do requests to different domains, and additional DNS calls.</p>\n<p>Another option is to do one request per dashboard and receive all the data that dashboard needs in one response. The most important downside of this - decrease in <a href=\"https://en.wikipedia.org/wiki/Perceived_performance\">perceived performance</a>, when user will not be able to see top graphs which are requested first, first, but will observe inactivity on the page for a long time and then everything will load. And this will not be possible when a user creates dashboard dynamically by adding widgets here and there. And will require a rewrite of server and client.</p>\n<p>But there is a possibility to do all request over one connection and then receive all responses over the same one:</p>\n<h2>WebSockets</h2>\n<p>First, for Nginx to pass WebSocket requests to the backend server, we need to change location configuration for our API like this:</p>\n<pre><code class=\"hljs language-nginx\">        <span class=\"hljs-attribute\">location</span> /api/ {\n            <span class=\"hljs-attribute\">proxy_pass</span>      http://backend:8080/; <span class=\"hljs-comment\"># this line was here before, the rest are added</span>\n            <span class=\"hljs-attribute\">proxy_http_version</span> <span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span>;\n            <span class=\"hljs-attribute\">proxy_set_header</span> Upgrade $http_upgrade;\n            <span class=\"hljs-attribute\">proxy_set_header</span> Connection <span class=\"hljs-string\">\"Upgrade\"</span>;\n            <span class=\"hljs-attribute\">proxy_set_header</span> Host $host;\n            <span class=\"hljs-attribute\">proxy_read_timeout</span> <span class=\"hljs-number\">3600s</span>;\n            <span class=\"hljs-attribute\">proxy_send_timeout</span> <span class=\"hljs-number\">3600s</span>;\n        }</code></pre>\n<p>Then, as we will send all the requests and receive all the responses over one connection, and they will be received not in the same order as they were sent, we need to figure out how to match requests with responses. That could be done using unique ids, which define to which chart each response belongs.</p>\n<p>So, we will replace our <code>loadData</code> function that called <code>fetch</code> with the following code:</p>\n<pre><code class=\"hljs language-javascript\"><span class=\"hljs-keyword\">var</span> ws = <span class=\"hljs-keyword\">new</span> WebSocket(<span class=\"hljs-string\">'ws://'</span> + <span class=\"hljs-built_in\">document</span>.domain + <span class=\"hljs-string\">':'</span> + location.port + <span class=\"hljs-string\">'/api/ws/'</span>);\n\nws.onopen = <span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span>(<span class=\"hljs-params\"></span>) </span>{\n    <span class=\"hljs-comment\">// Vue instance should be created after socket is open because otherwise </span>\n    <span class=\"hljs-comment\">// components could try to send requests before it opens, and will fail</span>\n    <span class=\"hljs-keyword\">new</span> Vue({\n      <span class=\"hljs-attr\">el</span>: <span class=\"hljs-string\">\"#app\"</span>,\n      <span class=\"hljs-attr\">data</span>: data\n    });\n}\n\n<span class=\"hljs-keyword\">var</span> socketSubscribers = {}; <span class=\"hljs-comment\">// will map request id's to repsponse handlers</span>\nws.onmessage = <span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\">event</span>) </span>{\n    <span class=\"hljs-keyword\">var</span> data = <span class=\"hljs-built_in\">JSON</span>.parse(event.data);\n    <span class=\"hljs-keyword\">var</span> subscriber = socketSubscribers[data.id];\n    <span class=\"hljs-keyword\">if</span>(subscriber) {\n        subscriber(data);\n        <span class=\"hljs-comment\">// <span class=\"hljs-doctag\">TODO:</span> maybe remove subscriber</span>\n    };\n};\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span> <span class=\"hljs-title\">get_unique_id</span>(<span class=\"hljs-params\"></span>) </span>{\n    <span class=\"hljs-comment\">// Will not work for multiple users, for production use some UUID implementation</span>\n    get_unique_id.uid = (get_unique_id.uid || <span class=\"hljs-number\">0</span>) + <span class=\"hljs-number\">1</span>;\n    <span class=\"hljs-keyword\">return</span> get_unique_id.uid\n}\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span> <span class=\"hljs-title\">loadData</span>(<span class=\"hljs-params\">widget, cb</span>) </span>{\n    <span class=\"hljs-comment\">// Load data for widget given, and when it is loaded - call cb</span>\n    <span class=\"hljs-keyword\">var</span> id = get_unique_id();\n\n    <span class=\"hljs-comment\">// Send request </span>\n    ws.send(<span class=\"hljs-built_in\">JSON</span>.stringify({\n        <span class=\"hljs-attr\">id</span>: id, \n        <span class=\"hljs-attr\">data</span>: widget,\n        <span class=\"hljs-attr\">size</span>: DATA_LEN,\n    }));\n    <span class=\"hljs-comment\">// Add subscriber for response with this id</span>\n    socketSubscribers[id] = <span class=\"hljs-function\"><span class=\"hljs-keyword\">function</span> (<span class=\"hljs-params\">data</span>) </span>{\n        cb(data.data);\n    };\n}</code></pre>\n<p>This code is artificially simplified to fit in this post, and for example, proper ID generation, handling of errors, reconnect in case of lost connection are not implemented.</p>\n<p>Let's also look at how the server is changed. We need to add a new handler for WebSocket endpoint:</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-meta\">@app.websocket(<span class=\"hljs-params\"><span class=\"hljs-string\">'/ws'</span></span>)</span>\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">websocket</span>(<span class=\"hljs-params\">request, websocket</span>):</span>\n    <span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>: <span class=\"hljs-comment\"># Run forever</span>\n        data = <span class=\"hljs-keyword\">await</span> websocket.recv() <span class=\"hljs-comment\"># when receiving request from socket</span>\n        \n        <span class=\"hljs-comment\"># start task to handle that, pass it socket</span>\n        asyncio.create_task(handle_socket_data(websocket, data)) \n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">handle_socket_data</span>(<span class=\"hljs-params\">websocket, data</span>):</span>\n    <span class=\"hljs-keyword\">try</span>:\n        json_data = json.loads(data)\n        data = json_data[<span class=\"hljs-string\">'data'</span>]\n        size = json_data.get(<span class=\"hljs-string\">'size'</span>, <span class=\"hljs-number\">10</span>)\n        <span class=\"hljs-keyword\">await</span> websocket.send(json.dumps(<span class=\"hljs-built_in\">dict</span>(\n            <span class=\"hljs-built_in\">id</span>=json_data[<span class=\"hljs-string\">'id'</span>],\n            data=<span class=\"hljs-keyword\">await</span> get_data(data, size)\n        )))\n    <span class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\">as</span> e:\n        <span class=\"hljs-keyword\">await</span> websocket.send(json.dumps(<span class=\"hljs-built_in\">dict</span>(\n            error=<span class=\"hljs-built_in\">str</span>(e)\n        )))\n        <span class=\"hljs-keyword\">return</span></code></pre>\n<p>The server is not as complex as front-end part, but it is just because we are not re-implemented router here. Which we are likely to do if our goal was to multiplex multiple requests over one WebSocket.</p>\n<p>So, unfortunately, Firefox does not have WebSocket debugger to see it's performance, but we used <code>console.time</code> to measure time from start of script execution to the moment when <code>CHARTS_COUNT</code> charts are finished loading, and it gives me 5215ms. This is a lot better than 29 seconds. 5-6 times better.</p>\n<p>Could we do this even better? Well, time of each request is random and between 1 and 5 seconds, so if we will have it under 5 seconds it will be just an accident, but if better means not only faster but maintainable, then yes.</p>\n<p>This code above is a very simple example. It becomes more complicated when you had different endpoints so you will need to reimplement router for WebSockets handler. Then if you have different HTTP methods, you will also need to add that into the router and into the WebSocket payload. Then, if you need auth, cache control, you will start to reimplement HTTP. And it has a lot of features. For example, the browser already has a cache for requests and is able to update it using different methods (Etag, If-Modified-Since). Frameworks already have routers, auth and stuff like that.</p>\n<p>Additionally, if you have microservice architecture, will you create WebSocket for each service? Or create a microservice proxy that connects to other microservices over HTTP and provides WebSocket interface? Or add it to the backlog and forget about it forever, because you will never get to it because you will have to support that huge pile of sh code you wrote to optimize page load time.</p>\n<p>So, let me show you a better way:</p>\n<h2>HTTP2</h2>\n<p>First and biggest task that we need to do in order to use HTTP2 is to have TLS certificate for our domain. If you are serious about your app, you should have them for https anyway. For our experiments we could generate a self-signed certificate for localhost using this command:</p>\n<pre><code class=\"hljs language-bash\">openssl req -x509 -out localhost.crt -keyout localhost.key \\\n  -newkey rsa:2048 -nodes -sha256 \\\n  -subj <span class=\"hljs-string\">'/CN=localhost'</span> -extensions EXT -config &#x3C;( \\\n   <span class=\"hljs-built_in\">printf</span> <span class=\"hljs-string\">\"[dn]\\nCN=localhost\\n[req]\\ndistinguished_name = dn\\n[EXT]\\nsubjectAltName=DNS:localhost\\nkeyUsage=digitalSignature\\nextendedKeyUsage=serverAuth\"</span>)</code></pre>\n<p>Then just add that certificate to Nginx container:</p>\n<pre><code class=\"hljs language-docker\"><span class=\"hljs-keyword\">COPY</span><span class=\"bash\"> localhost.crt /etc/ssl/certs/localhost.crt;</span>\n<span class=\"hljs-keyword\">COPY</span><span class=\"bash\"> localhost.key /etc/ssl/private/localhost.key;</span></code></pre>\n<p>And now, update <code>nginx.conf</code> server section with this:</p>\n<pre><code class=\"hljs language-nginx\">        <span class=\"hljs-attribute\">listen</span> <span class=\"hljs-number\">443</span> ssl http2 default_server;\n        <span class=\"hljs-attribute\">listen</span> [::]:<span class=\"hljs-number\">443</span> ssl http2 default_server;\n        <span class=\"hljs-attribute\">ssl_ciphers</span> EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5;\n\n        <span class=\"hljs-attribute\">ssl_certificate</span> /etc/ssl/certs/localhost.crt;\n        <span class=\"hljs-attribute\">ssl_certificate_key</span> /etc/ssl/private/localhost.key;</code></pre>\n<p>Now, when we open https://localhost:8083/ in a browser, and check network tab, we will see this:</p>\n<p><img src=\"/content/http2_network_debug.png\" alt=\"\" title=\"Requests with HTTP2\"></p>\n<p>5.3 seconds and all requests start at the same time. Same speed improvement as WebSockets, but this time we just changed Nginx config, and not touched front-end or back-end code at all.</p>\n<p>Additional benefits from using HTTP is that it is now a lot easier to debug (you could explore WebSocket frames using Chrome debugger), but you could not reproduce socket request using <code>curl</code>. Also, here we automatically get browser cache and compression of HTTP headers.</p>\n<p>Of course, some old browsers could have no support HTTP2, but this should not worry us, because the protocol is negotiated automatically.</p>\n<h2>Conclusion</h2>\n<p>If you really have reason and resources to use WebSockets - use WebSockets. If your only task was to optimize page load, and you wanted to decrease time requests spend in a blocked state - just turn on HTTP2, don't repeat my mistake of developing WebSocket solution just because you do not know about HTTP2. You do now.</p>"},"archives":[{"url":"/month/2021-10/page/1","id":"2021-10","count":1,"title":"2021-10"},{"url":"/month/2021-01/page/1","id":"2021-01","count":4,"title":"2021-01"},{"url":"/month/2020-12/page/1","id":"2020-12","count":1,"title":"2020-12"},{"url":"/month/2020-09/page/1","id":"2020-09","count":2,"title":"2020-09"},{"url":"/month/2020-08/page/1","id":"2020-08","count":2,"title":"2020-08"},{"url":"/month/2020-07/page/1","id":"2020-07","count":10,"title":"2020-07"},{"url":"/month/2020-06/page/1","id":"2020-06","count":7,"title":"2020-06"},{"url":"/month/2018-12/page/1","id":"2018-12","count":1,"title":"2018-12"}],"topics":[{"url":"/tag/MOOC/page/1","id":"MOOC","title":"MOOC","count":2},{"url":"/tag/SICP/page/1","id":"SICP","title":"SICP","count":20},{"url":"/tag/asm/page/1","id":"asm","title":"asm","count":1},{"url":"/tag/ideas/page/1","id":"ideas","title":"ideas","count":1},{"url":"/tag/notes/page/1","id":"notes","title":"notes","count":6},{"url":"/tag/on writing/page/1","id":"on writing","title":"on writing","count":3}]},"__N_SSG":true}